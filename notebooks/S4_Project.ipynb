{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84adb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy import linalg as la\n",
    "from scipy import special as ss\n",
    "from einops import rearrange, repeat, reduce\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "# Use 'notebook' instead for interactive plots\n",
    "%matplotlib inline\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('retina')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={\n",
    "    \"figure.dpi\":300,\n",
    "    'savefig.dpi':300,\n",
    "    'animation.html':'jshtml',\n",
    "    'animation.embed_limit':100, # Max animation size in Mb\n",
    "})\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('whitegrid') # or 'ticks'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f916a383-c7d9-4238-ba86-0d2df7d523c0",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2fc8a7b-d019-4ea5-8c1d-353f3ba2bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "def read_all_files(directory):\n",
    "    all_data = {}\n",
    "    for dirname, _, filenames in os.walk('../data/raw/forex'):\n",
    "        for i, filename in enumerate(filenames):\n",
    "            if i <5:\n",
    "                # print(os.path.join(dirname, filename))\n",
    "                file_path = os.path.join(dirname, filename)\n",
    "                if file_path.endswith('.csv'):\n",
    "                    # print(f\"Processing file: {file_path}\")\n",
    "                    parts = filename.split('_')\n",
    "                    file_current_pair = parts[2]  # Currency pair is at index 2\n",
    "                    file_year = int(parts[-1].split('.')[0])  # Year is the last element\n",
    "                    \n",
    "                    # print(f\"Currency pair: {file_current_pair}, Year: {file_year}\")\n",
    "                    data_frame_name = f'{file_current_pair}{file_year}_df'\n",
    "                    # print(f\"DataFrame name: {data_frame_name}\")  \n",
    "                    data = pd.read_csv(file_path, header=None)  # Read without header\n",
    "                    data.columns = ['date', 'time', 'open', 'high', 'low', 'close', 'amount']\n",
    "                    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'])\n",
    "                    # Set 'datetime' column as index\n",
    "                    data.set_index('datetime', inplace=True)\n",
    "                    data.drop(['date', 'time'], axis=1, inplace=True)  # Drop 'date' and 'time' columns\n",
    "          \n",
    "                    all_data[data_frame_name] = data\n",
    "                    # print(f\"Length of all_data_frames: {len(all_data)}\") \n",
    "    return all_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5f317a-be45-4d40-9ceb-86fbf3fc6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '../data/raw/forex'\n",
    "# current_pair = 'GBPAUD'\n",
    "# year = 2018\n",
    "all_forex_data = read_all_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a7e3541-8c2c-4baa-9fed-822f609cdab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Name: GBPAUD2018_df\n",
      "DataFrame Name: GBPAUD2019_df\n",
      "DataFrame Name: GBPAUD2020_df\n",
      "DataFrame Name: GBPAUD2021_df\n",
      "DataFrame Name: GBPAUD2022_df\n"
     ]
    }
   ],
   "source": [
    "for df_name in all_forex_data:\n",
    "    print(f\"DataFrame Name: {df_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf2d2b-be90-4c23-ad08-0ee1aecd3a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 371504 entries, 2018-01-01 17:02:00 to 2018-12-31 16:58:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   open    371504 non-null  float64\n",
      " 1   high    371504 non-null  float64\n",
      " 2   low     371504 non-null  float64\n",
      " 3   close   371504 non-null  float64\n",
      " 4   amount  371504 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 17.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a84a2ffa30>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = all_forex_data['GBPAUD2018_df']\n",
    "df.info()\n",
    "plt.plot(df['open'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9760c31-b47f-4e84-8188-fdb0d5051f26",
   "metadata": {},
   "source": [
    "Extract one day data for trial run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd41cf6-8e7a-4f63-a984-0a8c0a6e144b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 32049 entries, 2018-01-01 17:02:00 to 2018-01-31 23:59:00\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   open    32049 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 500.8 KB\n"
     ]
    }
   ],
   "source": [
    "mini = df.loc['2018-01','open']\n",
    "forex_df = pd.DataFrame({'open': mini})\n",
    "forex_df.index = pd.to_datetime(forex_df.index)\n",
    "forex_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c67ba-499e-4eb7-8ca2-5a597b87ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = df.loc['2018-02-01', 'open']\n",
    "# test_df = pd.DataFrame({'open': test_data})\n",
    "# test_df.index = pd.to_datetime(test_df.index)\n",
    "# test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3826afc5",
   "metadata": {},
   "source": [
    "Split data set into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_len = math.ceil(len(forex_df)*0.9)\n",
    "train_df_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab81b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = forex_df[:train_df_len].iloc[:,0]\n",
    "test_data = forex_df[train_df_len:].iloc[:,0]\n",
    "print(train_data.shape, test_data.shape)\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a589556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = np.reshape(train_data.values, (-1,1))\n",
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cfaf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = np.reshape(test_data.values, (-1,1))\n",
    "dataset_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e2996b",
   "metadata": {},
   "source": [
    "transform data into sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde50e66-36d8-4677-b9a2-7fb93b9705c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### feature engineering: date feature: date, year, week, month, lag feature, rolling feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff399b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 60 # number of time steps to look back\n",
    "X_train, y_train = [],[]\n",
    "for i in range(len(dataset_train)-sequence_length):\n",
    "    X_train.append(dataset_train[i:(i+sequence_length),0])\n",
    "    y_train.append(dataset_train[(i+1):(i+sequence_length+1),0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype =torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.float32)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 30 # number of time steps to look back\n",
    "X_test, y_test = [],[]\n",
    "for i in range(len(dataset_test)-sequence_length):\n",
    "    X_test.append(dataset_test[i:(i+sequence_length),0])\n",
    "    y_test.append(dataset_train[(i+1):(i+sequence_length+1),0])\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype =torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype = torch.float32)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556de419-43f4-46f4-8bb2-6774b9e42b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f51e57-9843-4929-bca1-92cad366e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create TensorDataset\n",
    "# dataset_train = TensorDataset(torch.from_numpy(X_train).float(),torch.from_numpy(y_train).float())\n",
    "# print(len(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12d8d3-31cb-45f0-876a-c83eefe882cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 50\n",
    "\n",
    "# # Create data loaders.\n",
    "# train_dataloader = DataLoader(train_df, batch_size=batch_size)\n",
    "# test_dataloader = DataLoader(test_df, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd119a63-cb53-4cbd-9444-e232e628da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.reset_index()\n",
    "# display(train_df.head())\n",
    "# test_df = test_df.reset_index()\n",
    "# display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d3afb-3f8a-474f-bbe3-aaeacb01f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8016007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for performing matrix scans faster\n",
    "# The HiPPO functions also have pedagogical sequential versions, so this cell is not required\n",
    "\n",
    "def shift_up(a, s=None, drop=True, dim=0):\n",
    "    assert dim == 0\n",
    "    if s is None:\n",
    "        s = torch.zeros_like(a[0, ...])\n",
    "    s = s.unsqueeze(dim)\n",
    "    if drop:\n",
    "        a = a[:-1, ...]\n",
    "    return torch.cat((s, a), dim=dim)\n",
    "\n",
    "def batch_mult(A, u, has_batch=None):\n",
    "    \"\"\" Matrix mult A @ u with special case to save memory if u has additional batch dim\n",
    "\n",
    "    The batch dimension is assumed to be the second dimension\n",
    "    A : (L, ..., N, N)\n",
    "    u : (L, [B], ..., N)\n",
    "    has_batch: True, False, or None. If None, determined automatically\n",
    "\n",
    "    Output:\n",
    "    x : (L, [B], ..., N)\n",
    "      A @ u broadcasted appropriately\n",
    "    \"\"\"\n",
    "\n",
    "    if has_batch is None:\n",
    "        has_batch = len(u.shape) >= len(A.shape)\n",
    "\n",
    "    if has_batch:\n",
    "        u = u.permute([0] + list(range(2, len(u.shape))) + [1])\n",
    "    else:\n",
    "        u = u.unsqueeze(-1)\n",
    "    v = (A @ u)\n",
    "    if has_batch:\n",
    "        v = v.permute([0] + [len(u.shape)-1] + list(range(1, len(u.shape)-1)))\n",
    "    else:\n",
    "        v = v[..., 0]\n",
    "    return v\n",
    "\n",
    "def interleave(a, b, uneven=False, dim=0):\n",
    "    \"\"\" Interleave two tensors of same shape \"\"\"\n",
    "    # assert(a.shape == b.shape)\n",
    "    assert dim == 0 # TODO temporary to make handling uneven case easier\n",
    "    if dim < 0:\n",
    "        dim = N + dim\n",
    "    if uneven:\n",
    "        a_ = a[-1:, ...]\n",
    "        a = a[:-1, ...]\n",
    "    c = torch.stack((a, b), dim+1)\n",
    "    out_shape = list(a.shape)\n",
    "    out_shape[dim] *= 2\n",
    "    c = c.view(out_shape)\n",
    "    if uneven:\n",
    "        c = torch.cat((c, a_), dim=dim)\n",
    "    return c\n",
    "\n",
    "\n",
    "def variable_unroll_general_sequential(A, u, s, op, variable=True):\n",
    "    \"\"\" Unroll with variable (in time/length) transitions A with general associative operation\n",
    "\n",
    "    A : ([L], ..., N, N) dimension L should exist iff variable is True\n",
    "    u : (L, [B], ..., N) updates\n",
    "    s : ([B], ..., N) start state\n",
    "    output : x (..., N)\n",
    "    x[i, ...] = A[i]..A[0] s + A[i..1] u[0] + ... + A[i] u[i-1] + u[i]\n",
    "    \"\"\"\n",
    "\n",
    "    if not variable:\n",
    "        A = A.expand((u.shape[0],) + A.shape)\n",
    "\n",
    "    outputs = []\n",
    "    for (A_, u_) in zip(torch.unbind(A, dim=0), torch.unbind(u, dim=0)):\n",
    "        s = op(A_, s)\n",
    "        s = s + u_\n",
    "        outputs.append(s)\n",
    "\n",
    "    output = torch.stack(outputs, dim=0)\n",
    "    return output\n",
    "\n",
    "def variable_unroll_general(A, u, s, op, compose_op=None, sequential_op=None, variable=True, recurse_limit=16):\n",
    "    \"\"\" Bottom-up divide-and-conquer version of variable_unroll.\n",
    "\n",
    "    compose is an optional function that defines how to compose A without multiplying by a leaf u\n",
    "    \"\"\"\n",
    "\n",
    "    if u.shape[0] <= recurse_limit:\n",
    "        if sequential_op is None:\n",
    "            sequential_op = op\n",
    "        return variable_unroll_general_sequential(A, u, s, sequential_op, variable)\n",
    "\n",
    "    if compose_op is None:\n",
    "        compose_op = op\n",
    "\n",
    "    uneven = u.shape[0] % 2 == 1\n",
    "    has_batch = len(u.shape) >= len(A.shape)\n",
    "\n",
    "    u_0 = u[0::2, ...]\n",
    "    u_1 = u[1::2, ...]\n",
    "\n",
    "    if variable:\n",
    "        A_0 = A[0::2, ...]\n",
    "        A_1 = A[1::2, ...]\n",
    "    else:\n",
    "        A_0 = A\n",
    "        A_1 = A\n",
    "\n",
    "    u_0_ = u_0\n",
    "    A_0_ = A_0\n",
    "    if uneven:\n",
    "        u_0_ = u_0[:-1, ...]\n",
    "        if variable:\n",
    "            A_0_ = A_0[:-1, ...]\n",
    "\n",
    "    u_10 = op(A_1, u_0_) # batch_mult(A_1, u_0_, has_batch)\n",
    "    u_10 = u_10 + u_1\n",
    "    A_10 = compose_op(A_1, A_0_)\n",
    "\n",
    "    # Recursive call\n",
    "    x_1 = variable_unroll_general(A_10, u_10, s, op, compose_op, sequential_op, variable=variable, recurse_limit=recurse_limit)\n",
    "\n",
    "    x_0 = shift_up(x_1, s, drop=not uneven)\n",
    "    x_0 = op(A_0, x_0) # batch_mult(A_0, x_0, has_batch)\n",
    "    x_0 = x_0 + u_0\n",
    "\n",
    "\n",
    "    x = interleave(x_0, x_1, uneven, dim=0) # For some reason this interleave is slower than in the (non-variable) unroll_recursive\n",
    "    return x\n",
    "\n",
    "def variable_unroll_matrix(A, u, s=None, variable=True, recurse_limit=16):\n",
    "    if s is None:\n",
    "        s = torch.zeros_like(u[0])\n",
    "    has_batch = len(u.shape) >= len(A.shape)\n",
    "    op = lambda x, y: batch_mult(x, y, has_batch)\n",
    "    sequential_op = lambda x, y: batch_mult(x.unsqueeze(0), y.unsqueeze(0), has_batch)[0]\n",
    "    matmul = lambda x, y: x @ y\n",
    "    return variable_unroll_general(A, u, s, op, compose_op=matmul, sequential_op=sequential_op, variable=variable, recurse_limit=recurse_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca58439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(measure, N, **measure_args):\n",
    "    # Laguerre (translated)\n",
    "    if measure == 'lagt':\n",
    "        b = measure_args.get('beta', 1.0)\n",
    "        A = np.eye(N) / 2 - np.tril(np.ones((N, N)))\n",
    "        B = b * np.ones((N, 1))\n",
    "    # Legendre (translated)\n",
    "    elif measure == 'legt':\n",
    "        Q = np.arange(N, dtype=np.float64)\n",
    "        R = (2*Q + 1) ** .5\n",
    "        j, i = np.meshgrid(Q, Q)\n",
    "        A = R[:, None] * np.where(i < j, (-1.)**(i-j), 1) * R[None, :]\n",
    "        B = R[:, None]\n",
    "        A = -A\n",
    "    # Legendre (scaled)\n",
    "    elif measure == 'legs':\n",
    "        q = np.arange(N, dtype=np.float64)\n",
    "        col, row = np.meshgrid(q, q)\n",
    "        r = 2 * q + 1\n",
    "        M = -(np.where(row >= col, r, 0) - np.diag(q))\n",
    "        T = np.sqrt(np.diag(2 * q + 1))\n",
    "        A = T @ M @ np.linalg.inv(T)\n",
    "        B = np.diag(T)[:, None]\n",
    "        B = B.copy() # Otherwise \"UserWarning: given NumPY array is not writeable...\" after torch.as_tensor(B)\n",
    "    elif measure == 'fourier':\n",
    "        freqs = np.arange(N//2)\n",
    "        d = np.stack([np.zeros(N//2), freqs], axis=-1).reshape(-1)[1:]\n",
    "        A = 2*np.pi*(-np.diag(d, 1) + np.diag(d, -1))\n",
    "        B = np.zeros(N)\n",
    "        B[0::2] = 2\n",
    "        B[0] = 2**.5\n",
    "        A = A - B[:, None] * B[None, :]\n",
    "        # A = A - np.eye(N)\n",
    "        B *= 2**.5\n",
    "        B = B[:, None]\n",
    "\n",
    "    return A, B\n",
    "\n",
    "def measure(method, c=0.0):\n",
    "    if method == 'legt':\n",
    "        fn = lambda x: np.heaviside(x, 0.0) * np.heaviside(1.0-x, 0.0)\n",
    "    elif method == 'legs':\n",
    "        fn = lambda x: np.heaviside(x, 1.0) * np.exp(-x)\n",
    "    elif method == 'lagt':\n",
    "        fn = lambda x: np.heaviside(x, 1.0) * np.exp(-x)\n",
    "    elif method in ['fourier']:\n",
    "        fn = lambda x: np.heaviside(x, 1.0) * np.heaviside(1.0-x, 1.0)\n",
    "    else: raise NotImplementedError\n",
    "    fn_tilted = lambda x: np.exp(c*x) * fn(x)\n",
    "    return fn_tilted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fddd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basis(method, N, vals, c=0.0, truncate_measure=True):\n",
    "    \"\"\"\n",
    "    vals: list of times (forward in time)\n",
    "    returns: shape (T, N) where T is length of vals\n",
    "    \"\"\"\n",
    "    if method == 'legt':\n",
    "        eval_matrix = ss.eval_legendre(np.arange(N)[:, None], 2*vals-1).T\n",
    "        eval_matrix *= (2*np.arange(N)+1)**.5 * (-1)**np.arange(N)\n",
    "    elif method == 'legs':\n",
    "        _vals = np.exp(-vals)\n",
    "        eval_matrix = ss.eval_legendre(np.arange(N)[:, None], 1-2*_vals).T # (L, N)\n",
    "        eval_matrix *= (2*np.arange(N)+1)**.5 * (-1)**np.arange(N)\n",
    "    elif method == 'lagt':\n",
    "        vals = vals[::-1]\n",
    "        eval_matrix = ss.eval_genlaguerre(np.arange(N)[:, None], 0, vals)\n",
    "        eval_matrix = eval_matrix * np.exp(-vals / 2)\n",
    "        eval_matrix = eval_matrix.T\n",
    "    elif method == 'fourier':\n",
    "        cos = 2**.5 * np.cos(2*np.pi*np.arange(N//2)[:, None]*(vals)) # (N/2, T/dt)\n",
    "        sin = 2**.5 * np.sin(2*np.pi*np.arange(N//2)[:, None]*(vals)) # (N/2, T/dt)\n",
    "        cos[0] /= 2**.5\n",
    "        eval_matrix = np.stack([cos.T, sin.T], axis=-1).reshape(-1, N) # (T/dt, N)\n",
    "#     print(\"eval_matrix shape\", eval_matrix.shape)\n",
    "    \n",
    "    if truncate_measure:\n",
    "        eval_matrix[measure(method)(vals) == 0.0] = 0.0\n",
    "    \n",
    "    p = torch.tensor(eval_matrix)\n",
    "    p *= np.exp(-c*vals)[:, None] # [::-1, None]\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6694c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPOScale(nn.Module):\n",
    "    \"\"\" Vanilla HiPPO-LegS model (scale invariant instead of time invariant) \"\"\"\n",
    "    def __init__(self, N, method='legs', max_length=1024, discretization='bilinear'):\n",
    "        \"\"\"\n",
    "        max_length: maximum sequence length\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        A, B = transition(method, N)\n",
    "        B = B.squeeze(-1)\n",
    "        A_stacked = np.empty((max_length, N, N), dtype=A.dtype)\n",
    "        B_stacked = np.empty((max_length, N), dtype=B.dtype)\n",
    "        for t in range(1, max_length + 1):\n",
    "            At = A / t\n",
    "            Bt = B / t\n",
    "            if discretization == 'forward':\n",
    "                A_stacked[t - 1] = np.eye(N) + At\n",
    "                B_stacked[t - 1] = Bt\n",
    "            elif discretization == 'backward':\n",
    "                A_stacked[t - 1] = la.solve_triangular(np.eye(N) - At, np.eye(N), lower=True)\n",
    "                B_stacked[t - 1] = la.solve_triangular(np.eye(N) - At, Bt, lower=True)\n",
    "            elif discretization == 'bilinear':\n",
    "                A_stacked[t - 1] = la.solve_triangular(np.eye(N) - At / 2, np.eye(N) + At / 2, lower=True)\n",
    "                B_stacked[t - 1] = la.solve_triangular(np.eye(N) - At / 2, Bt, lower=True)\n",
    "            else: # ZOH\n",
    "                A_stacked[t - 1] = la.expm(A * (math.log(t + 1) - math.log(t)))\n",
    "                B_stacked[t - 1] = la.solve_triangular(A, A_stacked[t - 1] @ B - B, lower=True)\n",
    "        self.register_buffer('A_stacked', torch.Tensor(A_stacked)) # (max_length, N, N)\n",
    "        self.register_buffer('B_stacked', torch.Tensor(B_stacked)) # (max_length, N)\n",
    "\n",
    "        vals = np.linspace(0.0, 1.0, max_length)\n",
    "        self.eval_matrix = torch.Tensor((B[:, None] * ss.eval_legendre(np.arange(N)[:, None], 2 * vals - 1)).T  )\n",
    "\n",
    "    def forward(self, inputs, fast=True):\n",
    "        \"\"\"\n",
    "        inputs : (length, ...)\n",
    "        output : (length, ..., N) where N is the order of the HiPPO projection\n",
    "        \"\"\"\n",
    "\n",
    "        L = inputs.shape[0]\n",
    "\n",
    "        inputs = inputs.unsqueeze(-1)\n",
    "        u = torch.transpose(inputs, 0, -2)\n",
    "        u = u * self.B_stacked[:L]\n",
    "        u = torch.transpose(u, 0, -2) # (length, ..., N)\n",
    "\n",
    "        if fast:\n",
    "            result = variable_unroll_matrix(self.A_stacked[:L], u)\n",
    "            return result\n",
    "        \n",
    "        c = torch.zeros(u.shape[1:]).to(inputs)\n",
    "        cs = []\n",
    "        for t, f in enumerate(inputs):\n",
    "            c = F.linear(c, self.A_stacked[t]) + self.B_stacked[t] * f\n",
    "            cs.append(c)\n",
    "        return torch.stack(cs, dim=0)\n",
    "\n",
    "    def reconstruct(self, c):\n",
    "        a = self.eval_matrix.to(c) @ c.unsqueeze(-1)\n",
    "        return a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPO(nn.Module):\n",
    "    \"\"\" Linear time invariant x' = Ax + Bu \"\"\"\n",
    "    def __init__(self, N, method='legt', dt=1.0, T=1.0, discretization='bilinear', scale=False, c=0.0):\n",
    "        \"\"\"\n",
    "        N: the order of the HiPPO projection\n",
    "        dt: discretization step size - should be roughly inverse to the length of the sequence\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.method = method\n",
    "        self.N = N\n",
    "        self.dt = dt\n",
    "        self.T = T\n",
    "        self.c = c\n",
    "        \n",
    "        A, B = transition(method, N)\n",
    "        A = A + np.eye(N)*c\n",
    "        self.A = A\n",
    "        self.B = B.squeeze(-1)\n",
    "        self.measure_fn = measure(method)\n",
    "        \n",
    "        C = np.ones((1, N))\n",
    "        D = np.zeros((1,))\n",
    "        dA, dB, _, _, _ = signal.cont2discrete((A, B, C, D), dt=dt, method=discretization)\n",
    "\n",
    "        dB = dB.squeeze(-1)\n",
    "\n",
    "        self.register_buffer('dA', torch.Tensor(dA)) # (N, N)\n",
    "        self.register_buffer('dB', torch.Tensor(dB)) # (N,)\n",
    "\n",
    "        self.vals = np.arange(0.0, T, dt)\n",
    "        self.eval_matrix = basis(self.method, self.N, self.vals, c=self.c) # (T/dt, N)\n",
    "        self.measure = measure(self.method)(self.vals)\n",
    "\n",
    "\n",
    "    def forward(self, inputs, fast=True):\n",
    "        \"\"\"\n",
    "        inputs : (length, ...)\n",
    "        output : (length, ..., N) where N is the order of the HiPPO projection\n",
    "        \"\"\"\n",
    "\n",
    "        inputs = inputs.unsqueeze(-1)\n",
    "        u = inputs * self.dB # (length, ..., N)\n",
    "\n",
    "        if fast:\n",
    "            dA = repeat(self.dA, 'm n -> l m n', l=u.size(0))\n",
    "            return variable_unroll_matrix(dA, u)\n",
    "        \n",
    "        c = torch.zeros(u.shape[1:]).to(inputs)\n",
    "        cs = []\n",
    "        for f in inputs:\n",
    "            c = F.linear(c, self.dA) + self.dB * f\n",
    "            cs.append(c)\n",
    "        return torch.stack(cs, dim=0)\n",
    "    \n",
    "\n",
    "\n",
    "    def reconstruct(self, c, evals=None): # TODO take in a times array for reconstruction\n",
    "        \"\"\"\n",
    "        c: (..., N,) HiPPO coefficients (same as x(t) in S4 notation)\n",
    "        output: (..., L,)\n",
    "        \"\"\"\n",
    "        if evals is not None:\n",
    "            eval_matrix = basis(self.method, self.N, evals)\n",
    "        else:\n",
    "            eval_matrix = self.eval_matrix\n",
    "\n",
    "        m = self.measure[self.measure != 0.0]\n",
    "\n",
    "        c = c.unsqueeze(-1)\n",
    "        y = eval_matrix.to(c) @ c\n",
    "        return y.squeeze(-1).flip(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad6fe2b-f95e-4be1-b0dd-d625e5ecb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "model = HiPPO(N=64)\n",
    "loss_fn =nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataloader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c5234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"N is vector, size of recurrent A matrix, know as 'd-state'\"\"\"\n",
    "# lti_methods = [\n",
    "#         'legs',\n",
    "#         'legt',\n",
    "#         'fourier',\n",
    "#     ]\n",
    "    \n",
    "# for method in lti_methods:\n",
    "model = HiPPO(method='legs', N=64, dt=1, T=len(X_train))\n",
    "loss_fn =nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feedc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4a675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c56abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbda706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff3da4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eadd90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ed8ff-ea42-4253-829f-9cf1abf6ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd10259-de10-483e-9da9-25c7155f3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113a1f7",
   "metadata": {},
   "source": [
    "Visualize the HiPPO function reconstruction theory in the spirit of the original paper. A random function $u(t)$ (black) is generated and processed sequentially by a HiPPO operator $x'(t) = A(t) x(t) + B(t) u(t)$. At the end of the sequence, the final state $x(t)$, which has dimension much smaller than the length of the sequence, can be used (via a linear projection) to approximately reconstruct the entire input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6fd1a4-1137-43ad-a24d-e2640aaaf4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forex_signal(forex_df):\n",
    "#     u = torch.tensor(forex_df, dtype=torch.float)\n",
    "#     return u\n",
    "\n",
    "# Plotting function\n",
    "def plot_forex_data(forex_df):\n",
    "    u = forex_df\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(np.arange(len(u)), u, 'k', linewidth=1.0, label='Forex Data')\n",
    "\n",
    "    # Additional plotting customization or analysis can be added here\n",
    "\n",
    "    plt.xlabel('Time (index)', labelpad=-20)\n",
    "    plt.show()\n",
    "\n",
    "plot_forex_data(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab8400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "np.random.seed(0)\n",
    "def plot(T, dt, N, freq):\n",
    "    vals = np.arange(0.0, T, dt)\n",
    "    \n",
    "    u = forex_signal(T, dt)\n",
    "    u = torch.tensor(u, dtype=torch.float)\n",
    "    u = u.to(device)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    offset = 0.0\n",
    "    plt.plot(vals, u.cpu()+offset, 'k', linewidth=1.0, label='Input u(t)')\n",
    "\n",
    "    # Linear Time Invariant (LTI) methods x' = Ax + Bu\n",
    "    lti_methods = [\n",
    "        'legs',\n",
    "        'legt',\n",
    "        'fourier',\n",
    "    ]\n",
    "    \n",
    "    for method in lti_methods:\n",
    "        hippo = HiPPO(method=method, N=N, dt=dt, T=T).to(device)\n",
    "        u_hippo = hippo.reconstruct(hippo(u))[-1].cpu()\n",
    "        plt.plot(vals[-len(u_hippo):], u_hippo, label=method)\n",
    "        \n",
    "    # Original HiPPO-LegS, which uses time-varying SSM x' = 1/t [ Ax + Bu]\n",
    "    # we call this \"linear scale invariant\"\n",
    "    lsi_methods = ['legs']\n",
    "    for method in lsi_methods:\n",
    "        hippo = HiPPOScale(N=N, method=method, max_length=int(T/dt)).to(device)\n",
    "        u_hippo = hippo.reconstruct(hippo(u))[-1].cpu()\n",
    "        plt.plot(vals[-len(u_hippo):], u_hippo, label=method+' (scaled)')\n",
    "\n",
    "\n",
    "    # plt.xlabel('Time (normalized)', labelpad=-10)\n",
    "    # plt.savefig(f'function_approximation.pdf', bbox_inches='tight')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "plot(T=train_df, dt=1, N=64, freq=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ae8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation code from \"How to Train Your HiPPO\"\n",
    "\n",
    "sns.set_style('ticks')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def plt_lines(x, y, color, size, label=None):\n",
    "    return plt.plot(x, y, color, linewidth=size, label=label)[0]\n",
    "\n",
    "def update_lines(ln, x, y):\n",
    "    ln.set_data(x, y)\n",
    "\n",
    "def animate_hippo(\n",
    "    method, \n",
    "    T=5, dt=5e-4, N=64, freq=20.0,\n",
    "    interval=100,\n",
    "    plot_hippo=False, hippo_offset=0.0, label_hippo=False,\n",
    "    plot_measure=False, measure_offset=-3.0, label_measure=False,\n",
    "    plot_coeff=None, coeff_offset=3.0,\n",
    "    plot_s4=False, s4_offset=6.0,\n",
    "    plot_hippo_type='line', plot_measure_type='line', plot_coeff_type='line',\n",
    "    size=1.0,\n",
    "    plot_legend=True, plot_xticks=True, plot_box=True,\n",
    "    plot_vline=False,\n",
    "    animate_u=False,\n",
    "    seed=2,\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    vals = np.arange(0, int(T/dt)+1)\n",
    "    L = int(T/dt)+1\n",
    "\n",
    "    u = torch.FloatTensor(whitesignal(T, dt, freq=freq))\n",
    "    u = F.pad(u, (1, 0))\n",
    "    u = u + torch.FloatTensor(np.sin(1.5*np.pi/T*np.arange(0, T+dt, dt))) # add 3/4 of a sin cycle\n",
    "    u = u.to(device)\n",
    "\n",
    "    hippo = HiPPO(method=method, N=N, dt=dt, T=T).to(device)\n",
    "    coef_hippo = hippo(u).cpu().numpy()\n",
    "    h_hippo = hippo.reconstruct(hippo(u)).cpu().numpy()\n",
    "    u = u.cpu().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    \n",
    "    if animate_u:\n",
    "        ln_u = plt_lines([], [], 'k', size, label='Input $u(t)$')\n",
    "    else:\n",
    "        plt_lines(vals, u, 'k', size, label='Input $u(t)$')\n",
    "    \n",
    "    if plot_hippo:\n",
    "        label_args = {'label': 'HiPPO reconstruction'} if label_hippo else {}\n",
    "        ln = plt_lines([], [], size=size, color='red', **label_args)\n",
    "\n",
    "    if plot_measure:\n",
    "        label_args = {'label': 'HiPPO Measure'} if label_measure else {}\n",
    "        ln_measure = plt_lines(vals, np.zeros(len(vals))+measure_offset, size=size, color='green', **label_args)\n",
    "\n",
    "    if plot_coeff is None: plot_coeff = []\n",
    "    if isinstance(plot_coeff, int): plot_coeff = [plot_coeff]\n",
    "    if len(plot_coeff) > 0:\n",
    "        ln_coeffs = [\n",
    "            plt_lines([], [], size=size, color='blue')\n",
    "            for _ in plot_coeff\n",
    "        ]\n",
    "        plt_lines([], [], size=size, color='blue', label='State $x(t)$') # For the legend\n",
    "        \n",
    "    \n",
    "    ### Y AXIS LIMITS\n",
    "    if plot_measure:\n",
    "        min_y = measure_offset\n",
    "    else:\n",
    "        min_y = np.min(u)\n",
    "        \n",
    "    if len(plot_coeff) > 0:\n",
    "        max_u = np.max(u) + coeff_offset\n",
    "    else:\n",
    "        max_u = np.max(u)\n",
    "\n",
    "\n",
    "    C = np.random.random(N)\n",
    "    s4 = np.sum(coef_hippo * C, axis=-1)\n",
    "    max_s4 = 0.0\n",
    "    if plot_s4:\n",
    "        ln_s4 = plt_lines([], [], size=size, color='red', label='Output $y(t)$')\n",
    "        max_s4 = np.max(s4)+s4_offset\n",
    "    \n",
    "    if plot_vline:\n",
    "        ln_vline = ax.axvline(0, ls='-', color='k', lw=1)\n",
    "\n",
    "    if plot_legend:\n",
    "        plt.legend(loc='upper left', fontsize='x-small')\n",
    "\n",
    "\n",
    "    def init():\n",
    "        left_endpoint = vals[0]\n",
    "        ax.set_xlim(left_endpoint, vals[-1]+1)\n",
    "        ax.set_ylim(min_y, max(max_u, max_s4))\n",
    "        ax.set_yticks([])\n",
    "        if not plot_xticks: ax.set_xticks([])\n",
    "        if not plot_box: plt.box(False)\n",
    "        return [] # ln,\n",
    "\n",
    "    def update(frame):\n",
    "        if animate_u:\n",
    "            xdata = np.arange(frame)\n",
    "            ydata = u[:frame]\n",
    "            update_lines(ln_u, xdata, ydata)\n",
    "\n",
    "        m = np.zeros(len(vals))\n",
    "        m[:frame] = hippo.measure_fn(np.arange(frame)*dt)[::-1]\n",
    "        xdata = vals\n",
    "        if plot_measure:\n",
    "            update_lines(ln_measure, xdata, m+measure_offset)\n",
    "        \n",
    "        if plot_hippo:   \n",
    "            ydata = h_hippo[frame] + hippo_offset\n",
    "            m2 = hippo.measure_fn(np.arange(len(ydata))*dt)[::-1]\n",
    "            # Remove reconstruction where measure is 0\n",
    "            ydata[m2 == 0.0] = np.nan\n",
    "            xdata = np.arange(frame-len(ydata), frame)\n",
    "            update_lines(ln, xdata, ydata)\n",
    "\n",
    "        if len(plot_coeff) > 0:\n",
    "            for coeff, ln_coeff in zip(plot_coeff, ln_coeffs):\n",
    "                update_lines(ln_coeff, np.arange(frame), coef_hippo[:frame, coeff] + coeff_offset)\n",
    "        if plot_s4: # Only scale case; scale case should copy plot_hippo logic\n",
    "            update_lines(ln_s4, np.arange(0, frame), s4[:frame] + s4_offset)\n",
    "            \n",
    "        if plot_vline:\n",
    "            ln_vline.set_xdata([frame, frame])\n",
    "\n",
    "        return []\n",
    "\n",
    "    ani = FuncAnimation(fig, update,\n",
    "                        frames=np.arange(0, int(T*1000/interval)+1)*int(interval/1000/dt),\n",
    "                        interval=interval,\n",
    "                        init_func=init, blit=True)\n",
    "\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ebbc9",
   "metadata": {},
   "source": [
    "Here, an input signal $u(t)$ (Black) is processed by the HiPPO operator $x'(t) = \\boldsymbol{A}x(t) + \\boldsymbol{B}u(t)$\n",
    " for 10000 steps, maintaining a state $x(t) \\in \\mathbb{R}^{64}$. At all times, the current state represents a compression of the history of $u(t)$ and can be linearly projected to approximately reconstruct it (Red). This approximation is optimal with respect to an exponentially-decaying measure (Green)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize HiPPO online reconstruction\n",
    "\n",
    "ani = animate_hippo(\n",
    "    'legs', # Try 'legt' or 'fourier'\n",
    "    T=5, dt=5e-4, N=64, interval=100,\n",
    "#     T=1, dt=1e-3, N=64, interval=200, # Faster rendering for testing\n",
    "    size=1.0,\n",
    "\n",
    "    animate_u=True,\n",
    "    plot_hippo=True, hippo_offset=0.0, label_hippo=True,\n",
    "    plot_s4=False, s4_offset=6.0,\n",
    "    plot_measure=True, measure_offset=-3.0, label_measure=True,\n",
    "    plot_coeff=[], coeff_offset=3.0,\n",
    "    plot_legend=True, plot_xticks=True, plot_box=True,\n",
    "    plot_vline=True,\n",
    ")\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af87022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize S4\n",
    "\n",
    "ani = animate_hippo(\n",
    "    'legs', # Try 'legt' or 'fourier'\n",
    "    T=5, dt=5e-4, N=64, interval=100,\n",
    "    size=1.0,\n",
    "\n",
    "    animate_u=True,\n",
    "    plot_hippo=False, hippo_offset=0.0, label_hippo=True,\n",
    "    plot_s4=True, s4_offset=6.0,\n",
    "    plot_measure=False, measure_offset=-3.0, label_measure=True,\n",
    "    plot_coeff=[0,1,2,3], coeff_offset=3.0,\n",
    "    plot_legend=True, plot_xticks=True, plot_box=True,\n",
    "    plot_vline=True,\n",
    ")\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save(\n",
    "    's4_operator_legs.gif',\n",
    "    savefig_kwargs={\n",
    "        # 'transparent': True,\n",
    "        # 'bbox_inches': 'tight',\n",
    "        'pad_inches': 0,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import TensorDataset\n",
    "dataset_train = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
